{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7379337,"sourceType":"datasetVersion","datasetId":4288371}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-09T13:22:37.198105Z","iopub.execute_input":"2024-04-09T13:22:37.199018Z","iopub.status.idle":"2024-04-09T13:22:38.267603Z","shell.execute_reply.started":"2024-04-09T13:22:37.198980Z","shell.execute_reply":"2024-04-09T13:22:38.266682Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/semeval2024task8/subtaskA_dev_monolingual.jsonl\n/kaggle/input/semeval2024task8/subtaskA_train_monolingual.jsonl\n/kaggle/input/semeval2024task8/subtaskA_train_multilingual.jsonl\n/kaggle/input/semeval2024task8/subtaskB_train.jsonl\n/kaggle/input/semeval2024task8/subtaskA_dev_multilingual.jsonl\n/kaggle/input/semeval2024task8/subtaskC_dev.jsonl\n/kaggle/input/semeval2024task8/subtaskB_dev.jsonl\n/kaggle/input/semeval2024task8/subtaskC_train.jsonl\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install evaluate","metadata":{"execution":{"iopub.status.busy":"2024-04-09T13:22:43.721730Z","iopub.execute_input":"2024-04-09T13:22:43.722618Z","iopub.status.idle":"2024-04-09T13:22:59.219625Z","shell.execute_reply.started":"2024-04-09T13:22:43.722582Z","shell.execute_reply":"2024-04-09T13:22:59.218612Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.18.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.2.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.22.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nCollecting responses<0.19 (from evaluate)\n  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.4)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading responses-0.18.0-py3-none-any.whl (38 kB)\nInstalling collected packages: responses, evaluate\nSuccessfully installed evaluate-0.4.1 responses-0.18.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom sklearn.model_selection import train_test_split\nfrom transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification, AdamW, set_seed\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.metrics import accuracy_score\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-04-09T13:23:06.424346Z","iopub.execute_input":"2024-04-09T13:23:06.424699Z","iopub.status.idle":"2024-04-09T13:23:15.222804Z","shell.execute_reply.started":"2024-04-09T13:23:06.424672Z","shell.execute_reply":"2024-04-09T13:23:15.221753Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def get_data(train_path, test_path, random_seed):\n\n    train_df = pd.read_json(train_path, lines=True)\n    test_df = pd.read_json(test_path, lines=True)\n    \n    train_df, val_df = train_test_split(train_df, test_size=0.2, stratify=train_df['label'], random_state=random_seed)\n\n    return train_df, val_df, test_df","metadata":{"execution":{"iopub.status.busy":"2024-04-09T13:23:17.010426Z","iopub.execute_input":"2024-04-09T13:23:17.010965Z","iopub.status.idle":"2024-04-09T13:23:17.016644Z","shell.execute_reply.started":"2024-04-09T13:23:17.010930Z","shell.execute_reply":"2024-04-09T13:23:17.015657Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"random_seed = 0\nset_seed(random_seed)\ntrain_path =  '/kaggle/input/semeval2024task8/subtaskA_train_multilingual.jsonl'\ntest_path =  '/kaggle/input/semeval2024task8/subtaskA_dev_multilingual.jsonl'\n\ntrain_df, valid_df, eval_df = get_data(train_path, test_path, random_seed)","metadata":{"execution":{"iopub.status.busy":"2024-04-09T13:31:47.744013Z","iopub.execute_input":"2024-04-09T13:31:47.744352Z","iopub.status.idle":"2024-04-09T13:31:52.997063Z","shell.execute_reply.started":"2024-04-09T13:31:47.744326Z","shell.execute_reply":"2024-04-09T13:31:52.996132Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_df","metadata":{"execution":{"iopub.status.busy":"2024-04-09T13:32:24.557053Z","iopub.execute_input":"2024-04-09T13:32:24.557782Z","iopub.status.idle":"2024-04-09T13:32:24.591998Z","shell.execute_reply.started":"2024-04-09T13:32:24.557737Z","shell.execute_reply":"2024-04-09T13:32:24.590756Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                                                     text  label   model  \\\n97884   This paper proposes an approach to learning a ...      0   human   \n92020   فیس بک کے بانی مارک زکربرگ نے بلا سوچے سمجھے ک...      0   human   \n64939   A DJ mix can be created using any number of di...      1  bloomz   \n55346   Jakarta -\\nKapolda Metro Jaya Irjen Idham Azis...      0   human   \n163088    We analyze the relationship between star for...      0   human   \n...                                                   ...    ...     ...   \n103298  \\nThis paper addresses the problem of predicti...      1  cohere   \n128253   If your hair is going to stay straightened an...      0   human   \n12019    The Association of International Schools in A...      1  cohere   \n163907    Image-guided depth completion aims to genera...      0   human   \n102948  \\nThis paper addresses the problem of how to l...      1  cohere   \n\n            source      id  \n97884     peerread   97884  \n92020         urdu   92020  \n64939      wikihow   64939  \n55346   indonesian   55346  \n163088       arxiv  163088  \n...            ...     ...  \n103298    peerread  103298  \n128253     wikihow  128253  \n12019    wikipedia   12019  \n163907       arxiv  163907  \n102948    peerread  102948  \n\n[137933 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n      <th>model</th>\n      <th>source</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>97884</th>\n      <td>This paper proposes an approach to learning a ...</td>\n      <td>0</td>\n      <td>human</td>\n      <td>peerread</td>\n      <td>97884</td>\n    </tr>\n    <tr>\n      <th>92020</th>\n      <td>فیس بک کے بانی مارک زکربرگ نے بلا سوچے سمجھے ک...</td>\n      <td>0</td>\n      <td>human</td>\n      <td>urdu</td>\n      <td>92020</td>\n    </tr>\n    <tr>\n      <th>64939</th>\n      <td>A DJ mix can be created using any number of di...</td>\n      <td>1</td>\n      <td>bloomz</td>\n      <td>wikihow</td>\n      <td>64939</td>\n    </tr>\n    <tr>\n      <th>55346</th>\n      <td>Jakarta -\\nKapolda Metro Jaya Irjen Idham Azis...</td>\n      <td>0</td>\n      <td>human</td>\n      <td>indonesian</td>\n      <td>55346</td>\n    </tr>\n    <tr>\n      <th>163088</th>\n      <td>We analyze the relationship between star for...</td>\n      <td>0</td>\n      <td>human</td>\n      <td>arxiv</td>\n      <td>163088</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>103298</th>\n      <td>\\nThis paper addresses the problem of predicti...</td>\n      <td>1</td>\n      <td>cohere</td>\n      <td>peerread</td>\n      <td>103298</td>\n    </tr>\n    <tr>\n      <th>128253</th>\n      <td>If your hair is going to stay straightened an...</td>\n      <td>0</td>\n      <td>human</td>\n      <td>wikihow</td>\n      <td>128253</td>\n    </tr>\n    <tr>\n      <th>12019</th>\n      <td>The Association of International Schools in A...</td>\n      <td>1</td>\n      <td>cohere</td>\n      <td>wikipedia</td>\n      <td>12019</td>\n    </tr>\n    <tr>\n      <th>163907</th>\n      <td>Image-guided depth completion aims to genera...</td>\n      <td>0</td>\n      <td>human</td>\n      <td>arxiv</td>\n      <td>163907</td>\n    </tr>\n    <tr>\n      <th>102948</th>\n      <td>\\nThis paper addresses the problem of how to l...</td>\n      <td>1</td>\n      <td>cohere</td>\n      <td>peerread</td>\n      <td>102948</td>\n    </tr>\n  </tbody>\n</table>\n<p>137933 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Check if CUDA is available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-04-09T13:32:27.841264Z","iopub.execute_input":"2024-04-09T13:32:27.842255Z","iopub.status.idle":"2024-04-09T13:32:27.849086Z","shell.execute_reply.started":"2024-04-09T13:32:27.842219Z","shell.execute_reply":"2024-04-09T13:32:27.848038Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"\n\nid2label = {0: \"human\", 1: \"machine\"}\nlabel2id = {\"human\": 0, \"machine\": 1}\nmodel_name = 'xlm-roberta-base'\n# Initialize the tokenizer and model\ntokenizer = XLMRobertaTokenizer.from_pretrained(model_name)\nmodel = XLMRobertaForSequenceClassification.from_pretrained(model_name, num_labels=2, id2label=id2label, label2id=label2id).to(device)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-09T13:32:32.265543Z","iopub.execute_input":"2024-04-09T13:32:32.265928Z","iopub.status.idle":"2024-04-09T13:32:35.739987Z","shell.execute_reply.started":"2024-04-09T13:32:32.265880Z","shell.execute_reply":"2024-04-09T13:32:35.739131Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2024-04-09T13:32:44.819615Z","iopub.execute_input":"2024-04-09T13:32:44.820090Z","iopub.status.idle":"2024-04-09T13:32:44.828174Z","shell.execute_reply.started":"2024-04-09T13:32:44.820056Z","shell.execute_reply":"2024-04-09T13:32:44.827142Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"XLMRobertaForSequenceClassification(\n  (roberta): XLMRobertaModel(\n    (embeddings): XLMRobertaEmbeddings(\n      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): XLMRobertaEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x XLMRobertaLayer(\n          (attention): XLMRobertaAttention(\n            (self): XLMRobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): XLMRobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): XLMRobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): XLMRobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (classifier): XLMRobertaClassificationHead(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"eval_df","metadata":{"execution":{"iopub.status.busy":"2024-04-09T14:03:39.678404Z","iopub.execute_input":"2024-04-09T14:03:39.678829Z","iopub.status.idle":"2024-04-09T14:03:39.694381Z","shell.execute_reply.started":"2024-04-09T14:03:39.678799Z","shell.execute_reply":"2024-04-09T14:03:39.693287Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"                                                   text  label    model  \\\n0     \\n\\nЮбилей Академии наук СССР, запланированный...      1  davinci   \n1     \\n\\nВ Мичигане был окончательно подведен итог ...      1  davinci   \n2     \\n\\nРежиссер Джош Транк, известный нам по филь...      1  davinci   \n3     \\n\\nПонедельник – день, когда в «Разведке» пыт...      1  davinci   \n4     \\n\\nДатская арт-группа Surrend провела провока...      1  davinci   \n...                                                 ...    ...      ...   \n3995  Zwischenfälle auf dem Nangpa La beziehen sich ...      1  chatGPT   \n3996  Zwischenmenschliche Beziehungen zählen zu den ...      1  chatGPT   \n3997  Das Zwölftonsystem, auch Dodekaphonie genannt,...      1  chatGPT   \n3998  Eine Zyklische Aktie ist eine Aktie, die aufgr...      1  chatGPT   \n3999  § 246 StGB ist eine Vorschrift im deutschen St...      1  chatGPT   \n\n       source    id  \n0     russian     0  \n1     russian     1  \n2     russian     2  \n3     russian     3  \n4     russian     4  \n...       ...   ...  \n3995   german  3995  \n3996   german  3996  \n3997   german  3997  \n3998   german  3998  \n3999   german  3999  \n\n[4000 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n      <th>model</th>\n      <th>source</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>\\n\\nЮбилей Академии наук СССР, запланированный...</td>\n      <td>1</td>\n      <td>davinci</td>\n      <td>russian</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\\n\\nВ Мичигане был окончательно подведен итог ...</td>\n      <td>1</td>\n      <td>davinci</td>\n      <td>russian</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\\n\\nРежиссер Джош Транк, известный нам по филь...</td>\n      <td>1</td>\n      <td>davinci</td>\n      <td>russian</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\\n\\nПонедельник – день, когда в «Разведке» пыт...</td>\n      <td>1</td>\n      <td>davinci</td>\n      <td>russian</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>\\n\\nДатская арт-группа Surrend провела провока...</td>\n      <td>1</td>\n      <td>davinci</td>\n      <td>russian</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3995</th>\n      <td>Zwischenfälle auf dem Nangpa La beziehen sich ...</td>\n      <td>1</td>\n      <td>chatGPT</td>\n      <td>german</td>\n      <td>3995</td>\n    </tr>\n    <tr>\n      <th>3996</th>\n      <td>Zwischenmenschliche Beziehungen zählen zu den ...</td>\n      <td>1</td>\n      <td>chatGPT</td>\n      <td>german</td>\n      <td>3996</td>\n    </tr>\n    <tr>\n      <th>3997</th>\n      <td>Das Zwölftonsystem, auch Dodekaphonie genannt,...</td>\n      <td>1</td>\n      <td>chatGPT</td>\n      <td>german</td>\n      <td>3997</td>\n    </tr>\n    <tr>\n      <th>3998</th>\n      <td>Eine Zyklische Aktie ist eine Aktie, die aufgr...</td>\n      <td>1</td>\n      <td>chatGPT</td>\n      <td>german</td>\n      <td>3998</td>\n    </tr>\n    <tr>\n      <th>3999</th>\n      <td>§ 246 StGB ist eine Vorschrift im deutschen St...</td>\n      <td>1</td>\n      <td>chatGPT</td>\n      <td>german</td>\n      <td>3999</td>\n    </tr>\n  </tbody>\n</table>\n<p>4000 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_df","metadata":{"execution":{"iopub.status.busy":"2024-04-09T14:03:50.728895Z","iopub.execute_input":"2024-04-09T14:03:50.729629Z","iopub.status.idle":"2024-04-09T14:03:50.742588Z","shell.execute_reply.started":"2024-04-09T14:03:50.729594Z","shell.execute_reply":"2024-04-09T14:03:50.741652Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"                                                     text  label   model  \\\n97884   This paper proposes an approach to learning a ...      0   human   \n92020   فیس بک کے بانی مارک زکربرگ نے بلا سوچے سمجھے ک...      0   human   \n64939   A DJ mix can be created using any number of di...      1  bloomz   \n55346   Jakarta -\\nKapolda Metro Jaya Irjen Idham Azis...      0   human   \n163088    We analyze the relationship between star for...      0   human   \n...                                                   ...    ...     ...   \n103298  \\nThis paper addresses the problem of predicti...      1  cohere   \n128253   If your hair is going to stay straightened an...      0   human   \n12019    The Association of International Schools in A...      1  cohere   \n163907    Image-guided depth completion aims to genera...      0   human   \n102948  \\nThis paper addresses the problem of how to l...      1  cohere   \n\n            source      id  \n97884     peerread   97884  \n92020         urdu   92020  \n64939      wikihow   64939  \n55346   indonesian   55346  \n163088       arxiv  163088  \n...            ...     ...  \n103298    peerread  103298  \n128253     wikihow  128253  \n12019    wikipedia   12019  \n163907       arxiv  163907  \n102948    peerread  102948  \n\n[137933 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n      <th>model</th>\n      <th>source</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>97884</th>\n      <td>This paper proposes an approach to learning a ...</td>\n      <td>0</td>\n      <td>human</td>\n      <td>peerread</td>\n      <td>97884</td>\n    </tr>\n    <tr>\n      <th>92020</th>\n      <td>فیس بک کے بانی مارک زکربرگ نے بلا سوچے سمجھے ک...</td>\n      <td>0</td>\n      <td>human</td>\n      <td>urdu</td>\n      <td>92020</td>\n    </tr>\n    <tr>\n      <th>64939</th>\n      <td>A DJ mix can be created using any number of di...</td>\n      <td>1</td>\n      <td>bloomz</td>\n      <td>wikihow</td>\n      <td>64939</td>\n    </tr>\n    <tr>\n      <th>55346</th>\n      <td>Jakarta -\\nKapolda Metro Jaya Irjen Idham Azis...</td>\n      <td>0</td>\n      <td>human</td>\n      <td>indonesian</td>\n      <td>55346</td>\n    </tr>\n    <tr>\n      <th>163088</th>\n      <td>We analyze the relationship between star for...</td>\n      <td>0</td>\n      <td>human</td>\n      <td>arxiv</td>\n      <td>163088</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>103298</th>\n      <td>\\nThis paper addresses the problem of predicti...</td>\n      <td>1</td>\n      <td>cohere</td>\n      <td>peerread</td>\n      <td>103298</td>\n    </tr>\n    <tr>\n      <th>128253</th>\n      <td>If your hair is going to stay straightened an...</td>\n      <td>0</td>\n      <td>human</td>\n      <td>wikihow</td>\n      <td>128253</td>\n    </tr>\n    <tr>\n      <th>12019</th>\n      <td>The Association of International Schools in A...</td>\n      <td>1</td>\n      <td>cohere</td>\n      <td>wikipedia</td>\n      <td>12019</td>\n    </tr>\n    <tr>\n      <th>163907</th>\n      <td>Image-guided depth completion aims to genera...</td>\n      <td>0</td>\n      <td>human</td>\n      <td>arxiv</td>\n      <td>163907</td>\n    </tr>\n    <tr>\n      <th>102948</th>\n      <td>\\nThis paper addresses the problem of how to l...</td>\n      <td>1</td>\n      <td>cohere</td>\n      <td>peerread</td>\n      <td>102948</td>\n    </tr>\n  </tbody>\n</table>\n<p>137933 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Tokenize text data from DataFrame\ntrain_encodings = tokenizer(train_df['text'].tolist(), truncation=True, padding=True)\neval_encodings = tokenizer(eval_df['text'].tolist(), truncation=True, padding=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-09T14:07:35.238168Z","iopub.execute_input":"2024-04-09T14:07:35.238644Z","iopub.status.idle":"2024-04-09T14:18:25.309410Z","shell.execute_reply.started":"2024-04-09T14:07:35.238607Z","shell.execute_reply":"2024-04-09T14:18:25.308400Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]).to(device) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx]).to(device)\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n    \n","metadata":{"execution":{"iopub.status.busy":"2024-04-09T14:18:39.709519Z","iopub.execute_input":"2024-04-09T14:18:39.710114Z","iopub.status.idle":"2024-04-09T14:18:39.716397Z","shell.execute_reply.started":"2024-04-09T14:18:39.710084Z","shell.execute_reply":"2024-04-09T14:18:39.715512Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = CustomDataset(train_encodings, train_df['label'].tolist())\neval_dataset = CustomDataset(eval_encodings, eval_df['label'].tolist())","metadata":{"execution":{"iopub.status.busy":"2024-04-09T14:18:43.469209Z","iopub.execute_input":"2024-04-09T14:18:43.469579Z","iopub.status.idle":"2024-04-09T14:18:43.477748Z","shell.execute_reply.started":"2024-04-09T14:18:43.469549Z","shell.execute_reply":"2024-04-09T14:18:43.476654Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"for i,data in enumerate(train_dataset):\n    print(data)\n    if(i>10):\n        break","metadata":{"execution":{"iopub.status.busy":"2024-04-09T14:31:11.762760Z","iopub.execute_input":"2024-04-09T14:31:11.763658Z","iopub.status.idle":"2024-04-09T14:31:11.965397Z","shell.execute_reply.started":"2024-04-09T14:31:11.763625Z","shell.execute_reply":"2024-04-09T14:31:11.964530Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"{'input_ids': tensor([     0,   3293,  15122,  26171,      7,    142,  51515,     47,  52080,\n            10,    484, 109109,    366,   2189,  17368,    142,     22,    587,\n           820,      9,  50718,  51744,    108,  82451,      6, 159958,      4,\n           678,     70, 157167,  54700,  60213,    450,     70,    484, 109109,\n        140992,     83,   4393,  80866,     41,  10484,      5,    581,  55300,\n            83, 151575,    297,    645,   6626,   5570,   2053,   3509,      7,\n            15,  10429,     31, 111056,    136,     62,  80091,    247,    237,\n          5299,    237,     10,  21261,   2053,   3509,  33444,    214,     47,\n         12937,  33938,      5,   3293,     83,     10,  18652,      4,   5299,\n         71924,    297,  15122,      4,   3129,  51776,     10,  35845,    538,\n          5299, 170920,  61353,     23,     70,   3173,    111,    142,     22,\n           587,    820,      9,  50718,  51744,    678,   3060,   1927,  58838,\n             7,     15,     13,      5,    177,      5,   2053,      6, 172562,\n          8305,    121, 179665,   6953,    247,    136,   4527,      7,    442,\n            47, 139392,  80866,     41,  10484,      4,    678,     70,   7398,\n          6982,    297,  92940,    450,  80866,     41,  10484,    621,   1286,\n         36510,   5844,   3501,   3789,    484, 109109,  23113,   8780,      7,\n         39210,    538,  11814,     23,     70, 163136,      4,    136,    831,\n           186,  27211,    297,    390,     51,   4448, 122009, 131126, 133325,\n            15,   1021,  69211,     42,    678,  80866,   1284,    959,    484,\n        109109,    366,   6953,    194,     87,  22113,    450,  80866,     83,\n          1286,  36510,   5844,   3501,     70,   5570,    484, 109109,  23113,\n          8780,      7,      4,   1284,   7068,  13438,      4,   3542,   2685,\n          6183,   2499,     41,  10484,     23,   2499,    111,    935,  17262,\n          2053,   3509,      7,   7440,     70,   5570,  23113,   8780,      7,\n           621,     51,   2886,     47, 141621,     70,   4393,    484, 109109,\n             7,    111,     70,     41,   1294,     32,     87,      5,     13,\n             5,    621,   1836,   6183,     70,   2965,   2053,   3509,      7,\n            47,   7639,  58437,     70,  36510,  54613,     53,    111,  80866,\n            32,  22376,      4,     23,  69407,    111,   2367,    935,   3299,\n         30698,      7,      4,   2367,      6, 175921,    111,  80866,  14602,\n           442,  20653,   4527,     32,     87,      5,     13,      5,   3642,\n          5045,    111,     70,   4173,  36510,  54613,     53,     23,  80866,\n            83,    935,   3299,  19048,     47, 141621,     32,  22376,      4,\n         14602,    442,    765,    333,    162,     90,     23,  69407,    111,\n            70,  20623,    111,     41,  10484,    450,    442,  17660,      7,\n            47, 139392,     32,   9925,     83,      4,     87,  36663,     47,\n          2046,     10,  11522,  10422,    111,    959,   1660,     70,    661,\n          7804,  80973,   1639,    111,  80866,      4,   1284,     70,   8561,\n          2481,    111,   2367,    935,   3299,     83,  19048,     47, 141621,\n             4,    136,     70,   3871,    100,   4173,  36510,  54613,     53,\n         35845,     47,     70,   2053,   3509,      7,    398,  28007,    645,\n             5,  31384, 124409,  62548,     47,    903,      4,     99,     70,\n          4034,    111, 140978,    190,      4,    398,    237,  33657,    450,\n           442,     25,      7,    182,    820,     47, 105237,  27489,  80866,\n             5,   2583,   8306,  20653,   7639,    903,      4,    136,    903,\n         37202,     47,    186,   1286,     10,  63805,    111,     70,  36510,\n         54613,     53,    111,  80866,   3501,  23937,  37076,     15, 143321,\n         30646,      7,    163,     47,     70,   9655,    111,   3642,   5045,\n           111,  80866,     83,     70,   3299,  20653,  12663,   1916,    194,\n          4997,      4,     87,   2806,   6183,    765,   1884,     71,     47,\n           765,  51592,   1286,  35107,    111,     70,  52895,    111,  80866,\n            41,  10484,    935,   3299, 139392,      7,      4,  30210,      5,\n           100,     70,  17932,   2831,    111,     70, 219836,      4,    645,\n            70,    159, 110776,  16271,   2053,   3509,      5, 209052,  25958,\n             4,   3229,     70,     41,   1294,     83,  99825,      9,   5037,\n           297,      4,     23,   2367,  48322,     83,    442,      2],\n       device='cuda:0'), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'), 'labels': tensor(0, device='cuda:0')}\n{'input_ids': tensor([     0,  43730,  24407,    216,      6,  90401, 115988,   9304,   8258,\n        173280,    778,  23101,  35069,   1597,  31765,   1597,  11561,   1568,\n         32286,   3210,   7314, 177374,    216,   4199,  25423,   1597,    288,\n         25478,  30649,    140, 156329,   2526,    639,  46177,  13142,    907,\n          3351,   7411,   1541,  43730,  24407,  32286,    317, 115988,   9304,\n          8258, 173280,    778,   4481,  79384,  26323,    523,  46308,    140,\n          1689,  39865,    140,   5363,    904,    288,  77470,   4566,    376,\n           216,   4199,   4481, 112115,    904,    499,  49419,    907,   3706,\n          1999,  76174, 112261, 110495,    140,  14021,    216,  51143,    216,\n          1533,    504,  43730,  24407,  46308,    140,   5363,    904,    216,\n        164618,    288,  38958,    317,    639,   5042, 115988,   9304,   8258,\n        173280,    778,   4894,    639,    924,   5503,    754, 108684,    554,\n         10878,  27977,   8598,   6597,    504,  20241,   7778,   1578,    490,\n           754,    288,  77470,   4566,    376,    216,   4199, 124874,   2067,\n         43503,  15035,  15410,  16634,  89957,    490,     65,  70191,  25488,\n         89957,  49957,   6408, 112115,    904,    523,   8641, 135597,   1578,\n          4116,    504,  13364,  15368,    778,  43730,  24407,    523,  46308,\n           140,   5363,    904,    523,   8787,  15472, 117330,    523,   4894,\n          4566,    924,  79384,  26323,    523,  10078,  76851,   9499, 125449,\n         16412,    639,    376,  11277,   6514,  34240,  32286,    317,  15368,\n           778,   4894,   5503,    754, 217493,    523,  31822, 185862,    504,\n          8641, 135597,   1578,    490,   5503,    754,  37943,    907,  35903,\n           554,  98339,    140,  65165,    504,  20241,   7778,   1578,    376,\n         11277,    716,    499,  18869,   4566,    924,   1938,  89756,  48854,\n        130114,   8065,    490, 127456,    140,  26048,   5461,    523,  10494,\n        131317,   2929,    907,    639,  18075,   5503, 170641,    216,  44396,\n           288, 215056,  48712,    140,   1923,  12738,  67815,  26048,    904,\n           778,  17460,   4894,    924,  43730,  24407,    754,   3485,  33140,\n           746,  10417, 158996,    523,   8641, 225945,    639,  66661,  45019,\n         12155,    216, 203822,    554,  77470,    258,   2047,    926,  23859,\n          5867,    317,  86000,  15410,  16634,  89957,    490,     65,  70191,\n         25488,  89957,    216,   4863,  46308,    140,   9499,    523,  64983,\n          3235,  11886,   7815,   1469,    288, 146734,   1568,   9675, 150569,\n           639,      2,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1],\n       device='cuda:0'), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'), 'labels': tensor(0, device='cuda:0')}\n{'input_ids': tensor([     0,     62,  22828,  17664,    831,    186,  75935,  17368,   2499,\n         14012,    111,  12921,  10975, 103391,      4,   1284,    903,  17997,\n          1221,  32153, 183037,     98,   3642,     47,  28282,    442,    678,\n            62,   2661,   1507,   9251,      5,   3293,  55300,  83687,      7,\n        105233,  48716,  18215,  86723,      7,  28032,   3129,    398,     25,\n          1181,   3687,  11651,  52336,    707,  40059,      7,    111,  19612,\n             5,   2583,   1543,   2843,   7413,   3060,  80234,   6305,     99,\n         11249,    717,    873,    893,  87673,  13703, 103687,     56,    390,\n          7880, 215528,  93124,      5,    581,  25632, 167934,  41591,    398,\n            25,    107,  16031,    678,  62822,  13909,  41018,      7,   6044,\n           237,  73432,  78303,      7,    136,  56136,   1916,   8305,   8026,\n             7,      5,   4263,    398,     25,     71,  43257,  30698,   1286,\n          1672,  17664,    214,  65133,  19612,  15490,  19441,     47,  35142,\n        105237,    678,  13909,      7,   7068,  12765,   1810,   2446,  44583,\n            47,  13676,    214,  14804,    180,   7710,  13038,  14493,     90,\n         64457,      5,   4857,   4092, 110324,  11389,  13794,  20662,  42659,\n             7, 134031,   3642,     47,   3249,  40956,      7,  20779, 191722,\n         26040,   3525, 102678,  54877,  31949, 109613,     13,  75169,   4420,\n         17164,    297,   4912,  21138,   3688,   2174,    398,   3871,   4358,\n         20600,    214,     62,   2661,   1507,   9251,    209,  44891,    329,\n         31949,     47,     70, 101758,  65290,   2182,  10932,     70,  49119,\n        135016,     67,     70,     44, 223353,     58,   8026,  35735, 105866,\n         33233,     70,   2663,  55516,   1299,    111,     27, 151313,    142,\n         32134,  55969,   2583,   5608,   1957,   6626,  84797,  18215,  86723,\n             7, 108975,  35064,     70,  27331,  20928,     74,  36849,  15044,\n           111,   8382,  86723,      7,    221,   1836,  15504,  57571,      5,\n         32255,  86723,      7,  33636,     70,  25737,    136,   7108, 135137,\n        119578,      7, 107013,    538,      5,  41974,  42724,      7,    360,\n           188,  55969,      7,    717,  15190,     10,  11531,     98,    188,\n         40101,   5609,    111,     70,  17664,     56,  42856,  24911,      9,\n          2940,      9, 138810,   6863,      6,      5,    634,    334,      4,\n             6,      5,   2676,    363,      4,      6,      5,     11,  32920,\n          3021, 111938,  11435,  80560,   3934,   3129,  30441,  18215,  86723,\n           132,      7,     16,    398,     25,    272, 133291,      5,  76556,\n         49814,   1836,     25,   1181,   9842,  75169, 191082,   3229,     70,\n          1528,   4034,      7,   1257,      5,   4263,    398,  32599,     47,\n         87388,     10,  11531,   1295,     70, 215692,   1660,  16401,   7565,\n         68847,  12960,  18158,    214,     98,    442,     74,  20594,    221,\n         36849,      7,    756,    111,     70,  55769,  82424,  13379,  46132,\n            70,  43581,  86723,     25,      7,  16128,      5, 107172,      9,\n        181671,  23972,  69182,   2161,  32036,  76556,    398,     25,    272,\n        122799, 154107,    756,    111,     70,  52336,    398,   3444,     47,\n         26698,     23,    935,  17664,  41929,      9, 123278,    214,     98,\n            70,   5117,  28560,   9803,      7,     70, 148529,   5037,  21455,\n          7440,    398,    831, 126596,  67842,  53550,      7,  26719,  11301,\n         12620,  38352,      4, 163451,   1585,     71,      4,  21950,  90926,\n           136,  40956,  26847,      5,     27,      2,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1],\n       device='cuda:0'), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'), 'labels': tensor(1, device='cuda:0')}\n{'input_ids': tensor([     0,  18218,     20,   1136,   5877,     85,  36159,  49934,   6921,\n          1390,     87,  78439,   1155,    164,  17616,  73161, 174356,   1345,\n           458,   4453,  49934,    267,  30609, 136828,      5,     87,  78439,\n        103437,  70478, 171534,    123, 199945,  10460,  28009,   2486,  23318,\n         85721,   2570,   5441,      5,     44,  15017,    145,  27201,      9,\n           350,    145,  27201, 232006,  25370,  13672,  85721,   2570,   5441,\n          1259,      5, 194737,      9,  65945,    496,  51238,  23318,      4,\n          3830,  70478,  40801,   5232,  20862,  70478, 199945,   5441, 163383,\n             4,     58,   3441,     87,  78439,     45,   9017,     85,  36159,\n             4,  21951, 192711,   1832,    936,    669,      4,  18218,      4,\n         96339,  39695,  20155, 121268,      5,    908,    273,   3527,    752,\n        106765,   1136,   5877,     85,  10532,  38089,   1202, 108870,    462,\n          1111,    265,   9017,   1132,   8500,   3336,  12806,      4,   1136,\n          5877,    416, 192711,  78459,   3423,  46069,   3378,      4,  43531,\n         21045, 145312,  23342,     13,   2595,  36428,    384,  18404,   2864,\n           188,      4,    123,  56672,  66560,   2447,      5,  41474,    257,\n            45,   9017,     85,  36159,   5288, 230452,   1628, 159450, 193938,\n         18218,  32340,     90,  12506,   1177,    549,    123,  66560,   4738,\n         90940, 116893,  16701,     15,  18537,  46935,    464,     85,    194,\n            87,  78439,   1220, 173483,     79,  68741,    273,   1825,   4926,\n         52705,   2486,  30609,    462, 136828,      5,     44,  14055,    638,\n         73161, 174356,   1345,    458,   4453,      4, 193087,      4,     45,\n        193938,  18218,   1485,      4,  30609,    462,  14876,      4,    704,\n         17818,      4,    123, 136828,      4,     58,  91396,    879,      5,\n           602,   2327,   1202,  32340,     90,  42053,  66677,    172,   9017,\n            85,  36159,      4, 175656,  47031,    331,  18218,   2013,    636,\n         38326,    378,    724,  19057,      7,     12,  25073,    387,    112,\n          1491,    268,      2,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1],\n       device='cuda:0'), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'), 'labels': tensor(0, device='cuda:0')}\n{'input_ids': tensor([     0,   1401,   7968,     53,    731,     70,  76755,  17721,   6057,\n         27643,     15,  38406,    247,   1614, 137656,      4,    136,   1601,\n         29786,   1515,  65998,     23,     10, 121413,    111,  36225,  43573,\n          1272, 225495, 234737,      7,  17368,   2053,   1295,     70,  83241,\n            66,  16284,  17689, 181842,      5,   6422,  43240,    765,  32603,\n          3674,     70, 151618,  17721,  59215,    136, 234737,   1614, 137656,\n             4,    136, 234737,   1614, 137656,    136,   1601,  29786,   1515,\n         65998,      4,   1284,  44836,     13,  93192,      7,  33444,    214,\n           756,  17262,    111,   6097,  77336,      7,   1556,  47143,    297,\n         19264,  29888,      5,   1401,   7413,    142,     23,  37676,  76755,\n         17721, 234737,  59215,      6, 175921,     15,    420,    454,  38406,\n            16,    136,   1601,  29786,   1515,  65998,    168,      7,   2481,\n             4,  74481,   3674,  17368,     70, 225495,  84901,   2481,    168,\n             7,   2481,  44457,     99,     10, 156100,    214, 140909,    111,\n           382,   1096,   8353,   5759,   9621,    238,     15,    397,  50490,\n             5,    581,     91,  89059,    111,   1238,    454,  38406,  20209,\n             5,    391,   1019,     83,     20,  37509,   1019, 194692,  89678,\n         14664,    581,   1238,    454,  38406,    111, 234737,      7, 105866,\n            23,  27226,      9,  34609,   2481,  21334,      9,      7,  57965,\n         65998,      7,      4, 126175,  12465, 194692,  89678,   1662,      4,\n            83,  77546,   3501,    100, 234737,      7, 105866,     23,  11192,\n             9,  34609,   2481,   1601,  29786,   1515,  48052,      4, 126175,\n          9550, 194692,  89678,   2592,      5,   1401,   2843, 101637,   1601,\n         29786,  37499,      4,  59499,     47,   2363,      6, 178851,  25443,\n             4,   3934,  52770,    674,      9,    136,  16195,    820,      9,\n         50986,  76519,      5,    581,     23,  37676,  76755,  17721, 234737,\n          1238,    454,  38406,    136,  21334,      9,      7,  57965,    168,\n             7,   2481,     83,  35462,   3674,    390,  52770,    674,      9,\n         43257,   3501,  16195,    820,      9,  50986,   1601,  29786,  37499,\n             5,    360,  11192,      9,  34609,   2481,  48052,    111,   1601,\n         29786,  37499,      4,    642,   7413,     10,  77546,   1238,    454,\n         38406,     23,  16195,    820,      9,  50986,   1601,  29786,  37499,\n             4, 126175,   4235, 194692,  89678,   2485,      4,   3501,     23,\n         52770,    674,      9,  50986,   1601,  29786,  37499,      4, 107754,\n         14604, 194692,  89678,   2947,      5,    345,   6953,   7893,  82761,\n        114137,      4,    642,  39563,   6097,  50339,    136,     70,   8951,\n         16106,  57860,  17721, 234737,   1614, 137656,    136,  59215,      5,\n         32255,  50339, 117414,    450, 234737,  59215,     83, 195052,    390,\n         15044,     70,  84079,    289,  32070,    111,     70, 234737,     15,\n         53927,  12060,  76519,  80788,     18,  77546,  41170,      7,    111,\n         59215,   3142,     70,  21334,      9,      7,  57965,    168,      7,\n          2481,    111,     70,   1601,  29786,   1515,  65998,     15,  84396,\n             9,  34609,   2481,  56458,  10776,      7,  80788,     18,  92319,\n         41170,      7,    111,  59215,   3142,    136,   1601,  29786,   1515,\n             6, 178851,  25443,     15,  44689,    820,      9,  50986,   1601,\n         29786,  37499,  80788,     18,  77546,  41170,      7,    111,  59215,\n            99,  11192,    168,      7,  31075,    194,      2,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1],\n       device='cuda:0'), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'), 'labels': tensor(0, device='cuda:0')}\n{'input_ids': tensor([     0,  22576,      4,    450,     25,      7,     10, 143033,   9655,\n            47,  35166,      4,   1284,     87,     25,   1181,   8337,    442,\n           759,   2965,    738,      5,   9578,     70,   5369,      4,   2446,\n        100094,    111, 116625,  29394,   1556,  58621, 216479,     71,    136,\n         98816,      5,    360,     70,  11015,      4,   2685,    509,     10,\n          5915,    111,  33946,    136, 102919,   1363,    678,     70, 188768,\n        128746,    111,     70,  29394,     20,   5351,     70,   1207,    318,\n          7844,  43515,    111,     70,  32238,    223,   2940,    136,   6561,\n         36151,      7,    707,     70,    756,   3408,    111,     70,  70352,\n         25129,      5,  33306,      4,     23,   1286,  17309,  20028,      4,\n         47353,   1884,     70,    483,  21553,  52875,      7,    136,   3789,\n         27992,      7,    111,  20870,   8780,    765,  58621, 122925,    297,\n            70,   3917,   5941,   3395,  21455,   3726,      5,   9925,   8035,\n          2804,      4,    442,     25,      7,   2843,   5526,     47, 125296,\n           450,   6097,  27992,      7,    111,  95319,    621,    117,   5408,\n          2175,    297,    390,  21870,   1419,  94407,   2750,     54,    959,\n         33636,     70,  18410, 144732,    111,  22458,      7,    707,     70,\n        116625, 109208,    237,     10,  28271,      5,   1650,     25,      7,\n            51,  93771,     47, 112518,    756,  22458,      7,    678,     70,\n          5701, 187363,    707,  41591,    450,   1836,    621,    756, 209303,\n        162711,     47,  20870,   8780,      5,    360,  15824,      4,   5941,\n         22458,      7,  10932,     70,   8999,    621,  20697,   7941,     47,\n         30641,  21870,   8780,    136, 125568,  88669,    136, 100094,      5,\n          1061,     87,   2806,   5154,    450,  15044,   2446,  49726,    111,\n        116625,  29394,    136,     70,  29394,  68034,    765,  98816,    645,\n          1733,      5,   1401,    765,  24209,   1286, 107419,    111,     70,\n         27140,  30355,      9, 170272,    289,  37348,    450,    831,  37105,\n            47,  21870,   8780,      4,    136,     70,  48322,     23,   3129,\n          6097,  37348,   1940,      7,  24762,    678,  42615,      5,   1913,\n            70,   5701,   1733,      4,   2685,    621,   7464,   5941,  58867,\n        128746,    111, 116625,  29394,     47,  88898,    136,  77947,      4,\n           136,    642,   5608,  22223,    272,     47,     54,    221,    678,\n           142,   9803,   7086,    136,     10,  52101,    111,  15072,    136,\n         79975,   2481,      5,      2,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1],\n       device='cuda:0'), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'), 'labels': tensor(1, device='cuda:0')}\n{'input_ids': tensor([     0,    581,  42179,      7,  13379,    142,  49041,  51515,     47,\n        172096,    289,  36279,  52080,    450,     83, 117906,   2886,     23,\n         69407,    111,  15044,   2053,  13267,     15,   2606,   1297,    111,\n         27781,      7,     16,    237,   5299,    237,   3299,  27140,   2481,\n             5,    581,   5201,   6528,  50155,   2363,  55300,     83,     47,\n          4527,  96759,  13452,  17514,    100,      6, 157955,   2481,    456,\n         77391, 134629,    390,  23189, 192617, 115774,     98,   6097,  30378,\n            71,  66139,      5,    360,  17311,   1836,   7639,   3642,    903,\n           831,    186,  11814,    678,  53894,    108,  82451,  33120,      7,\n          3129,    621,  51529,     47,    765,  11192, 177399,   1284,   2843,\n        134729,   1295,    645,   1029,  19514,   3229,  25550,    297, 105237,\n         17368,  35358,   2517,    224,  16797, 150624,      5,    581,    481,\n         50339, 106804,     13,  88551, 136912,      7, 154186,     47,   5570,\n         51515,     90,   6044,    237, 130403,   6056,  20324,  47691,      5,\n         24714,    449,    927,      7,     12,   3293,   4488,  13379,      7,\n         40368,  21261,  25647,  26719,     70,   4527,    111,  96759,  13452,\n          1830,  35509,  60213,   4173,  10763,  53088,  33233,    678,  93766,\n        234873,      7,    100, 242122,  35358,  35066,    148,   3198, 171859,\n             7,    111,     70,  16750,    214,  27226,      9, 157955,  18811,\n          1363,      5,   1401,    344,   7432,     90,     12,   1650,   2806,\n           186,  80234,   2174,   1286,  41653,   3542,  62952,   1672,     70,\n         24763,  31425,    111,     70,  26171,     71, 234873,     20,     28,\n             5,    177,      5,      4,    442,  37202,   1884,   2685,   5608,\n         32316,   3060,   3917,     47,   9969,   6743,     70,   4393,  30492,\n          3378,  50944,    425,  93766,    538,  15490,  19441,     47, 143726,\n           538,  64549,    756,   7722,  80836,      7,    111, 107730,      9,\n          6056,   7077,      7,  56065,  20271,   4420,  36290,     11, 125682,\n          8305,   1733,     32,      2,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1],\n       device='cuda:0'), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'), 'labels': tensor(1, device='cuda:0')}\n{'input_ids': tensor([     0,   8622,     83,     10,   5915,    111,  68869,  75412,     23,\n        200166,    136,     10,   5915,    111,    110,  26391,   7366,    100,\n          2684,   3395,    450,  60899, 107314,     70,  72761, 239414,      5,\n         52455,   3395,    765,   2363,   4488, 146543,     23,  13893,    538,\n            47, 194785,  36356,      7,      5,    581,  11405,     83,     70,\n         11405,    111,    450,  68869,   8035, 226586,    297,      5,   1326,\n            10,   2614,   1728,     70,   2614,    350,  36356,     83,   1884,\n         89289,    100,  40111,    136,  40111,  32497,  11907,   6626,  21974,\n             5,  46673,    450,  16065,    136,    442,  24209,      7,   7941,\n            47,      6, 131145,     67, 198395,     47,    603,   2886,   8966,\n             5,   8622,     83,   2843,     10,  12096,    111, 135488,     19,\n          2481,  54940,   2614,  25306,    450,    398,   5078,    184,      5,\n         52455,   3395,    435,  71358,    111,  34391,    645,    373,  58838,\n             4,  68772,  16065, 194785,      7,     47,  27060,      5,  57549,\n           350,  36356,   1314,  56104,  25813,     23, 131126,      7,      4,\n         36766,     23,   4488,    707,     23,   1909,      7,    136,    442,\n            83,     10,   2265,  33120,    450,    831,   2046,    398,     21,\n           532,    707, 129745,    935,  80997,     15,   3190,    935,  55983,\n          2614,   9248,      4,   2174,     10,   8010,  34391,    111,     10,\n         34391,   2614,   9248,      4,    398,   2046,   3525,  48322,   5792,\n         22120,     47,   2856,      5,     16,  57549,   6048,     83,   1884,\n            10,  10176,  13379,    398,   2046,  11907,   5155,    678,    756,\n         12096,      7,    111,   6782, 122378,      7,    136,   3395, 220642,\n            47,    442,      5,   1650,     25,      7,    959,   1660,  49649,\n        239414,     47,     70,  48683,    450,  30482,   3395,  76367,   2886,\n             4,    442,     83,   5078,   6953,     70,  62122,  68034,      5,\n          1913,  19713,    100,    163, 109954,      5,   1326, 121293,   2614,\n         25306,    442,     83,  31895,  12921,    707,   3395,   2750,    831,\n          7464,  22729,   1257,   3229,  17669,    442,     83,  31895,  12921,\n             5,      2,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1],\n       device='cuda:0'), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'), 'labels': tensor(0, device='cuda:0')}\n{'input_ids': tensor([     0,  18826,    118,   5342,     83,     10, 127663,    289,  62816,\n          1295,  98848,   2750,   1556,   2809,  60213,     71,     23, 131259,\n         42840,      4,      6, 114205,  36549,      4,    136,  67842,   1143,\n           206,   8915,    184,      5, 151313,     71,    390,     70,  89176,\n        198394,   1419,  65124,    188,    823,  55662,   3771,      4,  18826,\n           118,   5342,   5117, 118775,     23,     70, 131259,  43613,     44,\n          6979,  55662,   3771,  57832,     58,     23,  28980,      5,  18826,\n           118,   5342,     83,     10,  22556,   7515,    678,     10,  35011,\n         50046,  51418,      4,     10,   4842,    951,     13,      4,    136,\n        117781,   5844,  50997,  46223,      5,   1529,     83,  51529,    100,\n          8035,    142,   2874,      9,  90865,    136,     10,  63134,  55474,\n             5,   1529,     83,  27983,  51592,  67788,   2069,      4,    290,\n         26518,      4,    136, 216806,   1239,    206,  29469,      5,  33306,\n             4,    764,   2843,   1556,     10,    324, 125251,  13048, 108654,\n           450,   1556,   7228,   4049,     10,  66165,   4126,  62816,    645,\n            70,   5369,      5,    581,  62816,   1556,  16792, 118775,     23,\n            10,  96551,    111,  12921,  57646,      7,      4,  26719,     10,\n         65771, 131259,  12877,  36549,    136,    142,  10127,   3674, 113976,\n          7639,      5,    581, 131259,      7,   3542,  91376,    390,  40368,\n         89176,  80299,   1314,      4,  26719,    823,  55662,   3771,     25,\n             7,  10002,  80299,    214,  14380,      5,    581, 113976,   7639,\n           509,   1831,    297,     23,  98848,  20271,     70,  11704,      7,\n           136,    509,   5700,  54940,  20020,    136, 116127,     10,   5062,\n             5,  18826,    118,   5342,     25,      7,   5700,   2481,   1556,\n          2843,  12441,     47,     70,  36049,    111,  67842,   1143,    206,\n          8915,    184,      4,  26719,    808,      9, 112107,      4,     47,\n          4778,      4,    136,  27528,      5,    581,  62816,   1556,  24209,\n            10,  15380,  47989,     23,  98848,    136,   1556,     10,  21334,\n         25632,    111,  35992,   2750,  43799,   1919,  40765,  27519,     11,\n             5,    262,  61518,   1919,   6494, 216473,      4,  18826,    118,\n          5342,   1556,  24209,     10,  66165,   4126,  62816,     23,  98848,\n             4,  51529,    100,   1919,  43198,      4,  16000,      4,    136,\n           324, 125251,  13048, 177283,      5,  18763,   5700,   2481,   1556,\n         28927,    297,    100,      8,  23662,      7,      4,    136,    764,\n         47143,      7,     10,  41147,    133,    111,  89176,   7426,  29394,\n         18925,      5,      2,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1],\n       device='cuda:0'), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'), 'labels': tensor(1, device='cuda:0')}\n{'input_ids': tensor([     0,  89389,  14851,  30719,     15,  57332,    714,  18237,  27898,\n            16,     83,     10, 188676, 101740,  53865,    136,  36770,  23182,\n         58585,      4,   2750, 112730,    237,     10,   4122,  28394,     56,\n             5,   1529, 112730, 136659,  27528,    136,  47763,     71,   1632,\n         69236,    100,     70, 146864,  15889,   7175,      4,    136,  33636,\n           297,   1919,  23295,     99,     70,   3576,  28811, 161912,      5,\n          1913,  11938,  17366,    764, 112730,    100, 174090,  21612,    145,\n             4,  35988,      4, 192536, 106076,    136,    563,      5,    441,\n             5, 161876,     23, 146864,      4,    237,   5299,    237,    100,\n         10445,  12741,     13,     23,  98848,    136, 172539,  47064,     23,\n         30715,      5,   1529,   5036,  43240,    237,     10,   6868,   4597,\n           136,  26808,     98, 101740,     98,     70, 188676,   1910,  86723,\n          1910,    304, 146864,      5,  11356,    214,  80997,   7422,     19,\n            23,  28129,   2581,      4,  14851,  30719,  26859,  75169, 101740,\n           678,   1919,   4000,  11938,  28129,   2581, 219997,   1491,  46367,\n            99,     70,  32070,    111,   2289,   1529, 109133,     47, 174090,\n         21612,    145,     99,     70,  32070,    111,   5035,  51404,  75169,\n           100, 174090,  21612,    145,      4,    764,  34377,    297,    100,\n            70, 188676,   1379,   8363,  15889,   7175,     23,  18374,  11704,\n             4,    611,   5369,  10332,      5,   1529,   7228,   1919,  22962,\n         34377,    100, 174090,  21612,    145,     23,     70, 188676,    116,\n          2208, 127152,  10542,  20271,     70,  12898,   1104,  12231,  34003,\n             5,    360,  20414,  12839,      4,    764, 109133,     47,  35988,\n            23,     70,   2663,      9,    420,  20016, 188676,   4265,   4172,\n        102995,  16070,      5,   1529,  24765,    297,  15700,  23552,   6602,\n           678,     70, 174090,  21612,    145,      4,  12960,  67229,    214,\n          1919,  53019,      5,    360,  18982,  13867,      4,  14851,  30719,\n           509, 111628,    297,   1810,     47, 192536, 106076,     23,     70,\n        188676,    106,    271, 127152,      4,    136, 104902,     70,  11938,\n         19916,  82641,    100,     70,   4265,   4172,     23,     70,  51065,\n        106540,  14851,  30719,  26859,   1919,  35988,  80997,     23,     70,\n         51065, 106540,   1529,    509,     10,   2831,    111,     70,  35988,\n          7175,    450,  27169,   3674,  48716,  28811,  15619, 159690,      7,\n          5120,   8884,   1295,     70,  21640,  13211,   1104,   8821,  48524,\n         15619, 233547,      5,  35988,   1902,  72856,     70,   5117,  14858,\n           138,   1104,    304,     99,   5368,     23,  88880,      5,    360,\n            70,  17932,   6712,      4,  14851,  30719,  21449,     98,    237,\n            10, 161740,     13,    100,      6,  14775,  12620,   8694,     33,\n        126891,  30719,      5,    423,  94131,   8108,     70,   6712, 134620,\n             4,  14851,  30719,  47763,     71,     70,   2704,  69236,     23,\n         35988,     25,      7,    116,   1104,   2389,  19916,      4,    136,\n        111670,     71,     70,  11938, 129745,    674,     23,     70, 233547,\n             5,  35988,    509,   7068,  27169,   3674,    390,  89176,  11938,\n            62,      5,    441,      5,   2392,    192,     23,     70, 128274,\n             9,  33870,      7,      5,  14851,  30719,   4163,   1919,  15889,\n         36356, 222521,     23,     70,  11891,   1104,  14773,   4265,   4172,\n         34003,      4,   3229,    764, 112730,    756,   3912, 192428,  27528,\n           136,  47763,     71,    611, 109458,    100,  35988,      5,   1529,\n           509,  35839,   1257,     47,     70,   5117, 146864,  15889,   7175,\n         14858,    111,   3525,  15889,  31095,   2460, 125815,      4,    136,\n         14851,  30719,   7228,   1919,  21640,  34377,     23,     70,   8055,\n         11891,   6712,  26548,  71006,      5,   1529, 112730,    142,  78301,\n         15889,   7175,   6712,     23,   7071,  10586,      4,   8108,    764,\n           509,  54324,     47,  89176,  11938,  10445,  12741,     13,     23,\n            70,  51065,  82490,    360,   1919,   5117,   6602,     99,  10445,\n         12741,     13,      4,  14851,  30719,   4734, 112730,  17262,  27528,\n            23,     70,  89176,  45378,     62, 102995,  16070,      2],\n       device='cuda:0'), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'), 'labels': tensor(0, device='cuda:0')}\n{'input_ids': tensor([     0,  17819,  19909,  60728,  72089,     15,  57332,    106,  18237,\n         41906,     16,     83,    142,  14941,  39329,      4,      6,  70035,\n             4,    136,  14364,      5,   1529,     83,  51529,    100,   1919,\n          4488,    678,     70,  25674, 113154,  33734,    136,     70,   9907,\n        146613,      4,    136,    100,   1919, 183851, 170894,      7,     98,\n         56101, 113976,      5,  19909,  60728,  72089,    509, 103122,     23,\n          9020,      5,  18763,  67373,      4,   7948,      4,    509,     10,\n         22072,      4,    136,   1919,  42732,      4,   4687,   2439,      4,\n           509,     10,  18276,   2452,   2242,      5,   1529,    509, 155629,\n           297,     99,   2907,      5,  10208,     25,      7,  19188,      4,\n          9020,      4,    136,     99,     70,  12535,    111,  24453, 131534,\n             4,   7440,    764,  12301,  14941,    136,  15672, 163136,      5,\n           360,  25695,      4,  19909,  60728,  72089,  33284,    297,     70,\n         25674, 113154,  33734,      4,   7440,    764,    509,     10,  32786,\n           111,     70,  20324,  14380,    100,  43606,   5369,      5,   1529,\n        118775,     23, 183851,  36049,      7,      4,  26719,    581, 116512,\n           111, 212059,      7,      4,   1301,   2583,  18852,   1650,      4,\n         11954,     25,      7,    239,  38648,     25,      7,   3731,     18,\n             4,    180,    927,  13817,      4,  18813,    636,    147,      4,\n           136,  83416,    238,  53946,    136, 230204,     33,  48850,  15901,\n         51952,      5,    360,  24427,      4,  19909,  60728,  72089,  33284,\n           297,     70,   9907, 146613,      4,   7440,    764, 118775,     23,\n            10,  14012,    111,  36049,      7,      4,  26719,    581,   6035,\n          1294,   5140,   3132,    111,  38660,   4970,      4,  79616,     62,\n           246,  56888, 182747,      4,    581,   6035,  62956,    111,   2609,\n          3466,      4,    136,   8302,  12175,      7,    136,  15678,      7,\n         16818,      5,   1529,   2843, 118775,     23,     70,   9907, 146613,\n            25,      7,  36049,    111,    581,  47443,    111,     70,  21434,\n             7,    237,   3362,  21413,  85217,      5,    360,  66044,     47,\n          1919,  36541,   4488,      4,  19909,  60728,  72089,   1556, 118775,\n            23,   5941,  56101, 113976,  36549,      4,  26719,  10074,    712,\n           820,      4,   6096,    391,   4205,    420,      4,    581,  44389,\n          6561,      7,      4,    581,  12133,      4,  23172,  43042,      4,\n           136,  52625,  40469,      5,   1529,   2843, 112730,     70,  31486,\n           111,   8414,      5,  21656,   2481,     23,     70,   4831,     25,\n             7,    581,  59784,    136, 181268,  17367,      5,  19909,  60728,\n         72089,   1556,   2843,  59121,    136,   8951,    297,     10,  14012,\n           111,  11301,      7,      4,  26719,     62,    159,  20016,  43731,\n           111,  96719,      4,   3129,    509,  27154,   3674,    100,    142,\n        183433,  60992,    100,  11345,   2356, 116512,      5,      2,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1],\n       device='cuda:0'), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'), 'labels': tensor(1, device='cuda:0')}\n{'input_ids': tensor([     0,   4265,   2271,  77193,    214, 128779,      4,  35509,     98,\n            70,  59797,  80836,    214,    111,  77556,   1779,      4,  11301,\n           142,   5526,  31486,     23, 144573,    136,  74216,    660, 118299,\n             4,  17163,    214,   1295,   4567,   2320,  96391,  25251,     47,\n        110436,  13909,      7,      5,    581,    481,  23718,     83,  84046,\n           390,  65833,  93905,  12404,    254,  26147, 164101,   5256,    100,\n          4806,   1295, 148431,  59797,  80836,      7,      5,  14467,  17883,\n             7,     47,  69307,  19914,      9,  17336,  12404,    254,  26147,\n           168,      7,  31075,    765, 157578,   1733,      9,     11,  44947,\n         17704, 101935,    111, 164101,   5256,     98,     70,  12989,    111,\n          1632,     23,  11341,      9,   4390,      9,   2347,      9,   3960,\n        128779,      5,  33306,      4,     70,  84079,      7,    111,     70,\n         12404,    254,  26147,  43904,    237,   5299,    237,     70,   1733,\n        105994,      7,    100, 154107,    136,  49146,   6496,  11651, 164101,\n          5256,  47143,  21334,    538,     51, 111118,   2822,      5,  11853,\n             4,    642, 195935,    538, 106804,     13,     10,   1601,   2271,\n           693,  18770,  64557,   4092,    111,  12404,  15866,  66695,    100,\n         14922,      7,      6, 120027,   1257,     47,  94131,      5,   1401,\n         12983,     70,  12404,    254,  26147,  14012,     98,     10,  72006,\n           587,  18695,   1601,   2271,    693,  18770,     23,   2773,   1733,\n           390,    163,    162,  53089,     70,  25534,  80208,    214,     47,\n            10,   3638,  12924,   5470,      5,   7644,    126,      4, 164101,\n          1363,      9,  32087,  14922,      7,    621, 206735,    297,    390,\n         96759,      9,     73,      9,   6032,  59797,  80836, 116987,  47353,\n             4, 134629,    390,     10,   6818,    271,    111,  25534,  80208,\n           214,  28032,     10,   8877, 191633,      5,  22929,  50339, 106804,\n            13,     70, 207116,    111, 172852, 128779,  15490,  12404,  15866,\n         66695,    678,  38516,    538,  52295,     71,  23718,      5,    360,\n         66044,      4,   2446,  28007,    502,   7438,     70,  59665,      7,\n           111,    351, 155159,    316,  12404,  15866,  66695,     23,   2446,\n         75186,     74,     70,      8,    408,     53,    111,     70,  59797,\n         80836, 116987,  34515,    645,  40368,  40859,  25632,     70,  61475,\n         21185,  34695,  91736,   1810,   9433,     90,    187,  72219,   1295,\n          9545,  21068,    707,   4989,      9,    150,   4126,   5977,  71232,\n         97264,      5,      2,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1],\n       device='cuda:0'), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'), 'labels': tensor(0, device='cuda:0')}\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define training parameters\nbatch_size = 16\nlearning_rate = 2.0e-5\nnum_epochs = 3","metadata":{"execution":{"iopub.status.busy":"2024-04-09T14:20:10.787480Z","iopub.execute_input":"2024-04-09T14:20:10.787886Z","iopub.status.idle":"2024-04-09T14:20:10.792544Z","shell.execute_reply.started":"2024-04-09T14:20:10.787848Z","shell.execute_reply":"2024-04-09T14:20:10.791394Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\neval_loader = DataLoader(eval_dataset, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-04-09T14:20:16.184126Z","iopub.execute_input":"2024-04-09T14:20:16.185026Z","iopub.status.idle":"2024-04-09T14:20:16.189782Z","shell.execute_reply.started":"2024-04-09T14:20:16.184989Z","shell.execute_reply":"2024-04-09T14:20:16.188677Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"\n# Define optimizer and loss function\noptimizer = AdamW(model.parameters(), lr=learning_rate)\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-04-09T14:20:54.668123Z","iopub.execute_input":"2024-04-09T14:20:54.668453Z","iopub.status.idle":"2024-04-09T14:20:54.680684Z","shell.execute_reply.started":"2024-04-09T14:20:54.668427Z","shell.execute_reply":"2024-04-09T14:20:54.679827Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"# Function for training\ndef train(model, optimizer, criterion, dataloader, num_epochs):\n    model.train()\n    for epoch in range(num_epochs):\n        running_loss = 0.0\n        for batch in tqdm(dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs}\", leave=False):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n\n            optimizer.zero_grad()\n\n            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n            loss = outputs.loss\n            print(loss)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item() * input_ids.size(0)\n\n        epoch_loss = running_loss / len(dataloader.dataset)\n        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n\n        \n# Function for evaluation\ndef evaluate(model, dataloader):\n    model.eval()\n    all_preds = []\n    all_labels = []\n    with torch.no_grad():\n        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n            input_ids = batch['input_ids']\n            attention_mask = batch['attention_mask']\n            labels = batch['labels']\n\n            outputs = model(input_ids, attention_mask=attention_mask)\n            preds = torch.argmax(outputs.logits, dim=1)\n\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    accuracy = accuracy_score(all_labels, all_preds)\n    print(f\"Accuracy: {accuracy:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-09T14:24:04.701723Z","iopub.execute_input":"2024-04-09T14:24:04.702571Z","iopub.status.idle":"2024-04-09T14:24:04.714039Z","shell.execute_reply.started":"2024-04-09T14:24:04.702537Z","shell.execute_reply":"2024-04-09T14:24:04.713140Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"# # Train the baseline model\n# print(\"Training Baseline Model...\")\n# train(model, optimizer, criterion, train_loader, num_epochs)\nprint(\"Evaluating Baseline Model...\")\nevaluate(model, eval_loader)","metadata":{"execution":{"iopub.status.busy":"2024-04-09T14:32:38.535366Z","iopub.execute_input":"2024-04-09T14:32:38.536111Z","iopub.status.idle":"2024-04-09T14:34:45.521752Z","shell.execute_reply.started":"2024-04-09T14:32:38.536080Z","shell.execute_reply":"2024-04-09T14:34:45.520761Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stdout","text":"Evaluating Baseline Model...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 250/250 [02:06<00:00,  1.97it/s]","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.5030\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}